name: Weekly Water Scraper

on:
  schedule:
    - cron: '0 8 * * 1' # Mondays at 8am UTC
  workflow_dispatch:

permissions:
  contents: write

jobs:
  scrape-and-update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.9'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Run Scrapers
        run: |
          python scrape_water_allocations.py
          python scrape_water_plans.py

      - name: Commit and Push Data
        run: |
          git config --global user.name 'GitHub Action'
          git config --global user.email 'action@github.com'
          git add qld_water_allocations.csv qld_water_plans.csv
          # Only commit if files changed
          git diff --quiet && git diff --staged --quiet || (git commit -m "Update water data $(date +'%Y-%m-%d')" && git push)


### **Summary of Tasks**
1.  **Create** the new file `scrape_water_plans.py` in GitHub.
2.  **Update** the existing `scrape_water_allocations.py` with the code above.
3.  **Update** the `.github/workflows/weekly_scrape.yml` file to run both.
4.  **Run** the workflow manually one time to generate both CSVs.
5.  **Update** your `dashboard.py` (I can provide the code for the updated dashboard once you have the two CSVs ready!).
